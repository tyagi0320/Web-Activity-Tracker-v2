# ğŸŒ Track-Sphere: A Dockerized Kafka Pipeline for Real-Time Web Activity Tracking

A full-stack, real-time Web Activity Tracking Platform that captures and visualizes user browsing behavior using a custom-built Chrome extension. 
The project leverages a robust microservices architecture featuring Kafka for high-throughput event streaming, PostgreSQL for reliable data persistence, 
Grafana for insightful analytics and Docker for scalable containerization â€” all deployed on an AWS EC2 instance with HTTPS support via NGINX reverse proxy.

<br>

## ğŸ“Œ Features

-ğŸ“¦ Real-time data pipeline: Events (e.g., page visits) are tracked instantly and processed through a Kafka stream into a PostgreSQL database.

-ğŸŒ Browser extension: Custom Chrome extension captures session-level data like URL, timestamp, browser, platform, and user-agent.

-ğŸ“Š Live dashboard: Grafana visualizes traffic trends, browser/platform usage, and session timelines in an admin-accessible dashboard.

-â˜ï¸ Production-ready: End-to-end deployment on AWS EC2 using Docker Compose with SSL encryption, reverse proxy (NGINX), and persistent volumes.

-ğŸ› ï¸ Modular & Maintainable: Clear separation between the Kafka producer (Node.js backend), consumer, and frontend collection logic.

<br>

## ğŸ“ Architecture

                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               ğŸŒ User's Browser       
                        â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
                        â”‚  Chrome Extension (JS)      â”‚
                        â”‚  - Captures URL + Meta data â”‚
                        â”‚  - Sends HTTP POST â†’        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           ğŸš€ Backend API (Express)  
                        â”‚  - Validates incoming data â”‚
                        â”‚  - Extracts IP/User-Agent  â”‚
                        â”‚  - KafkaJS Producer sends  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              ğŸŸ  Kafka Topic            
                        â”‚  - Topic: `web-activity`   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           ğŸ§  Kafka Consumer (Node.js) 
                        â”‚  - Subscribes to topic       â”‚
                        â”‚  - Inserts into PostgreSQL   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           ğŸ—ƒï¸ PostgreSQL Database      
                        â”‚  - Table: `activity_logs`  â”‚
                        â”‚  - Stores session, event,  â”‚
                        â”‚    browser, IP, etc.       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           ğŸ“Š Grafana (on Port 3001)  
                        â”‚  - Queries PostgreSQL      â”‚
                        â”‚  - Visualizes analytics    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                      ğŸ³ All services run in Docker
                      ğŸ”’ HTTPS via NGINX Reverse Proxy (443)

<br>

## âš™ï¸ Tech Stack

| Layer        | Technology         |
|--------------|--------------------|
| Event Source | Chrome Extension   |
| Messaging    | Kafka + Zookeeper  |
| Backend API  | Node.js (Express)  |
| DB           | PostgreSQL         |
| Analytics    | Grafana            |
| Security     | HTTPS via NGINX    |
| Infra        | Docker Compose     |
| Cloud        | AWS EC2            |

<br>

## ğŸš€ Getting Started (Development)

### âœ… Prerequisites

- Docker & Docker Compose
- Git
- Node.js (for local backend testing)
- AWS Account

### ğŸ“ Project Structure

```bash
WEB-ACTIVITY-TRACKER/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ kafkaProducer.js
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â””â”€â”€ server.js
â”‚
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ init.sql
â”‚   â”œâ”€â”€ db.js
â”‚   â”œâ”€â”€ consumer.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ package-lock.json
â”‚
â”œâ”€â”€ extension/
â”‚   â”œâ”€â”€ background.js
â”‚   â””â”€â”€ manifest.json
â”‚
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ fullchain.pem
â”‚   â”œâ”€â”€ privkey.pem
â”‚   â””â”€â”€ nginx.conf
â”‚
â”œâ”€â”€ secrets/                    # Keep your SSH Keys , AWS Keys here
â”œâ”€â”€ .env                        # Root env file for Docker Compose
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

<br>

# ğŸš€ Project Setup

<br>

## âœ… 1. Set Up EC2 and Clone Repository

### ğŸ›¡ï¸ Create EC2 Instance

1. Go to **AWS EC2 Dashboard** â†’ **Launch Instance**.
2. Choose **Ubuntu 22.04 LTS** (or **Amazon Linux 2**).
3. Select **t2.micro** (Free Tier eligible).
4. Configure storage:
   - Default is **8 GB**.
   - Max for Free Tier is **30 GB**.
5. Under **Security Group** settings:
   - Allow **SSH (port 22)** â€“ only for your IP (or open for web access).
   - Allow **HTTP (port 80)** and **HTTPS (port 443)** â€“ for web access.
   - Allow custom TCP ports:
     - `3000` â†’ backend server  
     - `3001` â†’ Nginx  
     - `9092` â†’ Kafka  
     - `5432` â†’ PostgreSQL (optional if accessing externally)  
     - `9000` or `3002` â†’ Grafana (optional)

### ğŸ“Œ Associate Elastic IP (Optional but Recommended)

1. Go to **Elastic IPs** in the AWS EC2 sidebar.
2. Allocate a new IP and associate it with your EC2 instance.
3. This ensures your instance has a **static IP**, even after restarts.


### ğŸ“¥ Set File Permissions for Key

After downloading your `.pem` key file:

```bash
chmod 400 your-key.pem
```

### ğŸš€ Connect to EC2

```bash
ssh -i your-key.pem ubuntu@<your-ec2-public-ip>
```

### ğŸ³ Install Docker & Docker Compose v2

```bash
sudo apt update
sudo apt install -y docker.io git

# Enable Docker service
sudo systemctl enable docker
sudo systemctl start docker

# Allow your user to run docker commands without sudo
sudo usermod -aG docker ubuntu
newgrp docker
```

### âœ… Install Docker Compose v2 (as CLI plugin)

```bash
mkdir -p ~/.docker/cli-plugins/
curl -SL https://github.com/docker/compose/releases/download/v2.24.2/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose
chmod +x ~/.docker/cli-plugins/docker-compose
```

### ğŸ” Verify Installation

To check Docker Compose version:

```bash
docker compose version
```

**Expected output:**
```bash
Docker Compose version v2.24.2
```

### ğŸ“¦ Clone the Repository

```bash
git clone https://github.com/tyagi0320/Web-Activity-Tracker-v2.git
cd Web-Activity-Tracker-v2
```

<br>

## âœ… 2. Configure `.env` Files

1) Create a `.env` file in the root:

```env
# PostgreSQL
PG_USER=webuser
PG_PASSWORD=webpass
PG_DB=webtracker
PG_HOST=postgres
PG_PORT=5432

# Kafka
KAFKA_BROKER=kafka:9092

# Grafana Admin
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=admin

```

2) Create a `.env` file in backend
```env
KAFKA_BROKER=kafka:9092
PORT=3000
```
<br>

### âœ… 3. Add SSL certificates

ğŸŒ Step 1: Create a DNS A Record
Log in to your domain provider (e.g., Namecheap, GoDaddy) and create a DNS record:

- Type: A
- Host: monitor
- Points to: Your EC2 Elastic IP (e.g., 13.234.123.45)
- TTL: Automatic / Default

This maps monitor.global-dev.tech to your EC2 instance.


ğŸ” Step 2: Install Certbot and Generate SSL Certificates
From your EC2 terminal:
 ```bash
 sudo apt install certbot
```

Then issue certificates (replace with your actual subdomain):

```bash
sudo certbot certonly --standalone -d monitor.global-dev.tech
```
ğŸ“ Step 3: Copy Certificates to nginx/ Folder
Navigate to the Web-Activity-Tracker/nginx directory and run:   
```bash
sudo cp /etc/letsencrypt/live/monitor.global-dev.tech/fullchain.pem .
sudo cp /etc/letsencrypt/live/monitor.global-dev.tech/privkey.pem
```
ğŸ’¡ Ensure nginx.conf uses /etc/ssl/fullchain.pem and /etc/ssl/privkey.pem paths inside the container.
These are mapped from the copied cert files during image build.

<br>

### âœ… 4. Start All Containers

```bash
docker compose up --build -d
```

<br>

### âœ… 5. Install the Chrome Extension

- Go to `chrome://extensions` 
- Enable **Developer Mode**
- Click **Load Unpacked**
- Select the `/extension` folder

NOTE: Similarly you can have your extension installed on other web browsers as well.

<br>

### âœ… 6. View Data in PostgreSQL

```bash
docker exec -it webactivitytracker-postgres-1 psql -U webuser -d webtracker
```

Run query:

```sql
SELECT * FROM activity_logs ORDER BY id DESC LIMIT 10;
```

<br>

### âœ… 7. ğŸ“Š Grafana Setup for Web Activity Tracker

**Step-1: Visit in your browser**

```
https://monitor.global-dev.tech/grafana
```

**Step-2: Login using Default credentials**

- Username: `admin`
- Password: `admin` (you'll be prompted to change it, change if required)

**Step-3: Add PostgreSQL as a Data Source**

1. Go to **Data Sources**
2. Click **"Add data source"**
3. Choose **PostgreSQL**
4. Fill in these details:

| Field     | Value            |
|-----------|------------------|
| Host      | `postgres:5432`  |
| Database  | `webtracker`     |
| User      | `webuser`        |
| Password  | `webpass`        |
| SSL Mode  | `disable`        |

5. Click **Save & Test**

*You should see: **Data source is working**

<br>

### âœ… 8. ğŸ“ˆ Create Dashboards

### 1. **Most Visited URLs**

```sql
SELECT
  url AS "URL",
  count(*) AS "Visits"
FROM activity_logs
GROUP BY url
ORDER BY "Visits" DESC
LIMIT 10;
```

- Visualization: `Bar gauge` 

---

### 2. **Event Count Over Time**

```sql
SELECT
  date_trunc('minute', timestamp) AS "Time",
  count(*) AS "Events"
FROM activity_logs
GROUP BY 1
ORDER BY 1;
```

- Visualization: `Time series`

---

### 3. **Platform Breakdown**

```sql
SELECT
  platform,
  count(*) AS "Count"
FROM activity_logs
GROUP BY platform;
```

- Visualization: `Bar chart`

---

### 4. **Browser Usage**

```sql
SELECT
  browser,
  count(*) AS "Count"
FROM activity_logs
GROUP BY browser;
```
- Visualization: `Pie chart`

<br>

# ğŸ‰ HURRAY! Dashboards Are Live! ğŸš€

You've made it! Your real-time web activity tracking system is fully operational :)

âš¡ï¸ **Powered By:**
- ğŸ˜ PostgreSQL â€” Persistently storing your activity logs.
- ğŸ§µ Kafka â€” Streaming your web events with high throughput and durability.
- ğŸŒ Chrome Extensions â€” Capturing browsing sessions directly from the userâ€™s browser.
- ğŸ“Š Grafana â€” Real-time visualizations that keep you in the loop.
- ğŸ³ Docker â€” Orchestrating everything in isolated, production-ready containers.
- ğŸ” SSL (HTTPS) â€” Securing all traffic via NGINX reverse proxy with Let's Encrypt certificates.

<br>

ğŸ“¡ **Whatâ€™s Happening Right Now:**
- Your Chrome extension is silently capturing page visits.
- Events are sent to the Kafka broker and processed by a Kafka consumer.
- Logs are inserted into PostgreSQL, ensuring durability and structure.
- Grafana dashboards reflect your browsing activity in real time.
- Thanks to NGINX + SSL, your API and dashboards are served securely over HTTPS.
- Docker Compose keeps all services up, portable, and easily deployable.

<br>

ğŸ§  **Learning from this project:**

âœ…  Dockerized microservices architecture

âœ…  Kafka event streaming system

âœ…  PostgreSQL-backed event logging

âœ…  Grafana monitoring stack

âœ…  SSL-secured NGINX reverse proxy

âœ…  Chrome extension integration

âœ… DNS + custom domain setup

<br>

## Author

ğŸ“§ Email: tharshit03@gmail.com  
ğŸ”— GitHub: [@tyagi0320](https://github.com/tyagi0320)

## License 

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
